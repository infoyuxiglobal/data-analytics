{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This is the shortened version of a longer notebook on advanced data operations with pandas called `dw3-full.ipynb` and available to you at *no extra-cost!*. This version of the notebook focuses only on join and indexing operations. The full version covers advanced (user-defined) groupby+aggregation, pivoting as well as join and indexing.  In the interest of time, the live-workshop will conver the short version only.\n",
    "\n",
    "## Content \n",
    "\n",
    "1. [Connecting to databases](#dbs)\n",
    "2. [Some advanced data operations](#advanced)\n",
    " 1. [Indexing](#indexing) \n",
    " 1. [Merge and Join](#joining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dw_utils3 module (v. 20181113)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from importlib import reload \n",
    "import sys \n",
    "\n",
    "sys.path.append( \"../\")\n",
    "import dw_utils3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_submit = dw_utils3.create_submitter(host='data-workshops.yuxiglobal.com', port=443, \n",
    "                       user=\"your.name@yourcompany.com\", # put your full yuxi email address here, including @yuxiglobal.com\n",
    "                       ws_key=\"xw3\", #this is the workshop key, don't change it \n",
    "                       token='your_token' ) #put the token that Mateo sent to you in an e-mail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT:** Set the path to data to the right value where you put your (e.g. `\"C:/Users/username/Downloads/\"`)\n",
    "If you put the data files for this workshop in the same directory as the notebook ('.ipynb' file) then, just set this to `\"./\"`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./\" # leave as  \"./\" if you put the data files next to the notebook file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"dbs\"> </div>\n",
    "## Section 1: **Non-interactive** demo:  connecting to databases (DBs)\n",
    "\n",
    "**Warning:** Don't try to run the cells in this section as they will surely produce errors, as you don't have *pyodbc* installed or a local DB to connect to....\n",
    "\n",
    "To connect to a DB you need the *pyodbc* module (library). This is usually not installed by default but can be easily installed with the following command (or via a terminal with `conda install -y pyodbc`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! conda install -y pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the `.connect` function inside this module to create a connection to any database \n",
    "(to which we have the right credentials) via the appropriate connection string. In this case I am connecting a PostgreSQL engine running on my own laptop (localhost). Note that regardless of where the server is, your client machine needs to have the appropriate ODBC driver installed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pyodbc.connect(  \"Driver=PostgreSQL Unicode(x64);Server=localhost;Database=postgres;Uid=user1;Pwd=pwd1\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With an established connection, there are two ways to issue queries and get data: \n",
    "    \n",
    "  1.  Use pandas `pd.read_sql` function to construct a Dataframe from a query.\n",
    "  2.  Use the lower level  `conn.execute()` to get rows from a query in an incremental way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Using pandas .read_sql() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "customer.shape = (10000, 8)\n"
     ]
    }
   ],
   "source": [
    "# %%timeit -n1 -r1\n",
    "customer = pd.read_sql( \"select * from customer limit 10000\",\n",
    "                        conn )\n",
    "print( 'customer.shape =', customer.shape ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>tier</th>\n",
       "      <th>phone</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>322061</td>\n",
       "      <td>Florentia</td>\n",
       "      <td>Monte</td>\n",
       "      <td>Schaumburg</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>4</td>\n",
       "      <td>2935400016</td>\n",
       "      <td>9010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>322062</td>\n",
       "      <td>Sandie</td>\n",
       "      <td>Fortunato</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>0</td>\n",
       "      <td>5781163827</td>\n",
       "      <td>2504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>322063</td>\n",
       "      <td>Suellen</td>\n",
       "      <td>Loveman</td>\n",
       "      <td>Topeka</td>\n",
       "      <td>Kansas</td>\n",
       "      <td>9</td>\n",
       "      <td>2048151384</td>\n",
       "      <td>34689.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>322064</td>\n",
       "      <td>Marylou</td>\n",
       "      <td>Tisak</td>\n",
       "      <td>North Lauderdale</td>\n",
       "      <td>Florida</td>\n",
       "      <td>4</td>\n",
       "      <td>2243819204</td>\n",
       "      <td>53040.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>322065</td>\n",
       "      <td>Sibeal</td>\n",
       "      <td>Back</td>\n",
       "      <td>Lancaster</td>\n",
       "      <td>Texas</td>\n",
       "      <td>2</td>\n",
       "      <td>2189676526</td>\n",
       "      <td>1330.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>322066</td>\n",
       "      <td>Georgina</td>\n",
       "      <td>Neushul</td>\n",
       "      <td>Lodi</td>\n",
       "      <td>California</td>\n",
       "      <td>2</td>\n",
       "      <td>5291650587</td>\n",
       "      <td>3739.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>322067</td>\n",
       "      <td>Cristal</td>\n",
       "      <td>Kubacki</td>\n",
       "      <td>Rapid City</td>\n",
       "      <td>South Dakota</td>\n",
       "      <td>8</td>\n",
       "      <td>6008016122</td>\n",
       "      <td>39207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>322068</td>\n",
       "      <td>Maris</td>\n",
       "      <td>Kimberley</td>\n",
       "      <td>Port Arthur</td>\n",
       "      <td>Texas</td>\n",
       "      <td>3</td>\n",
       "      <td>3631667023</td>\n",
       "      <td>25143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>322069</td>\n",
       "      <td>Aleda</td>\n",
       "      <td>Badulescu</td>\n",
       "      <td>Baytown</td>\n",
       "      <td>Texas</td>\n",
       "      <td>5</td>\n",
       "      <td>4822823293</td>\n",
       "      <td>14137.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>322070</td>\n",
       "      <td>Aridatha</td>\n",
       "      <td>Chafin</td>\n",
       "      <td>Taylorsville</td>\n",
       "      <td>Utah</td>\n",
       "      <td>5</td>\n",
       "      <td>4855148616</td>\n",
       "      <td>18062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>322071</td>\n",
       "      <td>Nicholle</td>\n",
       "      <td>Arky</td>\n",
       "      <td>Collierville</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>6</td>\n",
       "      <td>4913191639</td>\n",
       "      <td>99212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>322072</td>\n",
       "      <td>Amil</td>\n",
       "      <td>Berger</td>\n",
       "      <td>Wilmington</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>9</td>\n",
       "      <td>5210331260</td>\n",
       "      <td>38777.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>322073</td>\n",
       "      <td>Alessandra</td>\n",
       "      <td>Adame</td>\n",
       "      <td>Richardson</td>\n",
       "      <td>Texas</td>\n",
       "      <td>3</td>\n",
       "      <td>2249501132</td>\n",
       "      <td>8959.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>322074</td>\n",
       "      <td>Jemmie</td>\n",
       "      <td>Diller</td>\n",
       "      <td>Simi Valley</td>\n",
       "      <td>California</td>\n",
       "      <td>5</td>\n",
       "      <td>5192172221</td>\n",
       "      <td>45280.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>322075</td>\n",
       "      <td>Astrix</td>\n",
       "      <td>Nevins</td>\n",
       "      <td>Covington</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>7</td>\n",
       "      <td>6549277023</td>\n",
       "      <td>73390.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>322076</td>\n",
       "      <td>Elmira</td>\n",
       "      <td>Oman</td>\n",
       "      <td>Santa Cruz</td>\n",
       "      <td>California</td>\n",
       "      <td>9</td>\n",
       "      <td>2230662543</td>\n",
       "      <td>63994.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>322077</td>\n",
       "      <td>Vikki</td>\n",
       "      <td>Zelmanowitz</td>\n",
       "      <td>Lincoln</td>\n",
       "      <td>California</td>\n",
       "      <td>6</td>\n",
       "      <td>3699594820</td>\n",
       "      <td>69606.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>322078</td>\n",
       "      <td>Maressa</td>\n",
       "      <td>Lamensdorf</td>\n",
       "      <td>Pine Bluff</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2</td>\n",
       "      <td>6315758143</td>\n",
       "      <td>15667.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>322079</td>\n",
       "      <td>Kriste</td>\n",
       "      <td>Delacey</td>\n",
       "      <td>Casa Grande</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>0</td>\n",
       "      <td>5610812250</td>\n",
       "      <td>3521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>322080</td>\n",
       "      <td>Faye</td>\n",
       "      <td>Jalisi</td>\n",
       "      <td>Wheeling</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>4</td>\n",
       "      <td>2452371533</td>\n",
       "      <td>41943.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cust_id  first_name    last_name              city         state  tier  \\\n",
       "0    322061   Florentia        Monte        Schaumburg      Illinois     4   \n",
       "1    322062      Sandie    Fortunato          Bartlett      Illinois     0   \n",
       "2    322063     Suellen      Loveman            Topeka        Kansas     9   \n",
       "3    322064     Marylou        Tisak  North Lauderdale       Florida     4   \n",
       "4    322065      Sibeal         Back         Lancaster         Texas     2   \n",
       "5    322066    Georgina      Neushul              Lodi    California     2   \n",
       "6    322067     Cristal      Kubacki        Rapid City  South Dakota     8   \n",
       "7    322068       Maris    Kimberley       Port Arthur         Texas     3   \n",
       "8    322069       Aleda    Badulescu           Baytown         Texas     5   \n",
       "9    322070    Aridatha       Chafin      Taylorsville          Utah     5   \n",
       "10   322071    Nicholle         Arky      Collierville     Tennessee     6   \n",
       "11   322072        Amil       Berger        Wilmington      Delaware     9   \n",
       "12   322073  Alessandra        Adame        Richardson         Texas     3   \n",
       "13   322074      Jemmie       Diller       Simi Valley    California     5   \n",
       "14   322075      Astrix       Nevins         Covington      Kentucky     7   \n",
       "15   322076      Elmira         Oman        Santa Cruz    California     9   \n",
       "16   322077       Vikki  Zelmanowitz           Lincoln    California     6   \n",
       "17   322078     Maressa   Lamensdorf        Pine Bluff      Arkansas     2   \n",
       "18   322079      Kriste      Delacey       Casa Grande       Arizona     0   \n",
       "19   322080        Faye       Jalisi          Wheeling      Illinois     4   \n",
       "\n",
       "         phone    sales  \n",
       "0   2935400016   9010.0  \n",
       "1   5781163827   2504.0  \n",
       "2   2048151384  34689.0  \n",
       "3   2243819204  53040.0  \n",
       "4   2189676526   1330.0  \n",
       "5   5291650587   3739.0  \n",
       "6   6008016122  39207.0  \n",
       "7   3631667023  25143.0  \n",
       "8   4822823293  14137.0  \n",
       "9   4855148616  18062.0  \n",
       "10  4913191639  99212.0  \n",
       "11  5210331260  38777.0  \n",
       "12  2249501132   8959.0  \n",
       "13  5192172221  45280.0  \n",
       "14  6549277023  73390.0  \n",
       "15  2230662543  63994.0  \n",
       "16  3699594820  69606.0  \n",
       "17  6315758143  15667.0  \n",
       "18  5610812250   3521.0  \n",
       "19  2452371533  41943.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Read and process a table record by record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method is not as simple as using Pandas directly but could be applied in cases where you don't want ir / can't read the results of a queary  at once. This could be the case if those results are so big that they don't fit in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (331741, 'Jeana', 'Shepsle', 'Hagerstown', 'Maryland', 9, 6575314094, 42042.0)\n",
      "first_name = Jeana\n",
      "last_name = Shepsle \n",
      "\n",
      "1 (331742, 'Sib', 'Di Felice', 'Santa Barbara', 'California', 7, 4362977952, 15050.0)\n",
      "first_name = Sib\n",
      "last_name = Di Felice \n",
      "\n",
      "2 (331743, 'Rickie', 'Pledger', 'Delano', 'California', 5, 3272289569, 11476.0)\n",
      "first_name = Rickie\n",
      "last_name = Pledger \n",
      "\n",
      "3 (331744, 'Nona', 'Heigemeir', 'Brownsville', 'Texas', 0, 4175238025, 5498.0)\n",
      "first_name = Nona\n",
      "last_name = Heigemeir \n",
      "\n",
      "4 (331745, 'Vivyan', 'Devita', 'Lancaster', 'Texas', 7, 5372658941, 25630.0)\n",
      "first_name = Vivyan\n",
      "last_name = Devita \n",
      "\n",
      "5 (331746, 'Megan', 'Finitsis', 'Jurupa Valley', 'California', 9, 2559482722, 118376.0)\n",
      "first_name = Megan\n",
      "last_name = Finitsis \n",
      "\n",
      "6 (331747, 'Aleda', 'Gabriel', 'San Antonio', 'Texas', 6, 6508374910, 27659.0)\n",
      "first_name = Aleda\n",
      "last_name = Gabriel \n",
      "\n",
      "7 (331748, 'Elva', 'Howey', 'Mansfield', 'Ohio', 4, 3178539777, 47939.0)\n",
      "first_name = Elva\n",
      "last_name = Howey \n",
      "\n",
      "8 (331749, 'Merralee', 'Rockwell', 'Kettering', 'Ohio', 4, 6176595809, 26937.0)\n",
      "first_name = Merralee\n",
      "last_name = Rockwell \n",
      "\n",
      "9 (331750, 'Amelita', 'Conway', 'Davis', 'California', 9, 3557229977, 3465.0)\n",
      "first_name = Amelita\n",
      "last_name = Conway \n",
      "\n",
      "10 (331751, 'Rubina', 'Shanks', 'Mesa', 'Arizona', 0, 2384315620, 7259.0)\n",
      "first_name = Rubina\n",
      "last_name = Shanks \n",
      "\n",
      "11 (331752, 'Corene', 'Mitra', 'Collierville', 'Tennessee', 9, 2427337195, 24293.0)\n",
      "first_name = Corene\n",
      "last_name = Mitra \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, record in enumerate( conn.execute( \"select * from customer\") ) :\n",
    "    print( i, record ) # A record is a tuple (without names :( )\n",
    "    print( 'first_name = '+ record[1])\n",
    "    print( 'last_name = '+ record[2], \"\\n\")\n",
    "    \n",
    "    if i > 10 :\n",
    "        break \n",
    "    # do something else with the data...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing results to a table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume you process your data and come up with a result. For example..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>tier</th>\n",
       "      <th>phone</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>331800</td>\n",
       "      <td>Davida</td>\n",
       "      <td>Cedarbaum</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>4</td>\n",
       "      <td>5689070376</td>\n",
       "      <td>22482.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>331801</td>\n",
       "      <td>Kym</td>\n",
       "      <td>Hottle</td>\n",
       "      <td>Brownsville</td>\n",
       "      <td>Texas</td>\n",
       "      <td>4</td>\n",
       "      <td>5273220578</td>\n",
       "      <td>3371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>331900</td>\n",
       "      <td>Barbara-Anne</td>\n",
       "      <td>Troisi</td>\n",
       "      <td>Baldwin Park</td>\n",
       "      <td>California</td>\n",
       "      <td>9</td>\n",
       "      <td>4102242190</td>\n",
       "      <td>18483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>331901</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>Drew</td>\n",
       "      <td>Moreno Valley</td>\n",
       "      <td>California</td>\n",
       "      <td>7</td>\n",
       "      <td>2968087426</td>\n",
       "      <td>8465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>332000</td>\n",
       "      <td>Sada</td>\n",
       "      <td>Abdulrazak</td>\n",
       "      <td>Carson</td>\n",
       "      <td>California</td>\n",
       "      <td>4</td>\n",
       "      <td>6520553137</td>\n",
       "      <td>8133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>332001</td>\n",
       "      <td>Cleo</td>\n",
       "      <td>Soares</td>\n",
       "      <td>Mansfield</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>8</td>\n",
       "      <td>5730383961</td>\n",
       "      <td>290471.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>332100</td>\n",
       "      <td>Glenda</td>\n",
       "      <td>Mcchesney</td>\n",
       "      <td>Lakewood</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>2</td>\n",
       "      <td>4833862965</td>\n",
       "      <td>14544.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>332101</td>\n",
       "      <td>Antonina</td>\n",
       "      <td>Ross-Degnan</td>\n",
       "      <td>Torrance</td>\n",
       "      <td>California</td>\n",
       "      <td>7</td>\n",
       "      <td>3611540956</td>\n",
       "      <td>24146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>332200</td>\n",
       "      <td>Katy</td>\n",
       "      <td>Maclaurin</td>\n",
       "      <td>Victorville</td>\n",
       "      <td>California</td>\n",
       "      <td>2</td>\n",
       "      <td>5961824651</td>\n",
       "      <td>85302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>332201</td>\n",
       "      <td>Liesa</td>\n",
       "      <td>Moeykens</td>\n",
       "      <td>Peoria</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>3</td>\n",
       "      <td>2350974211</td>\n",
       "      <td>4406.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>332300</td>\n",
       "      <td>Magdalena</td>\n",
       "      <td>Chehabi</td>\n",
       "      <td>Federal Way</td>\n",
       "      <td>Washington</td>\n",
       "      <td>8</td>\n",
       "      <td>6811170301</td>\n",
       "      <td>9055.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>332301</td>\n",
       "      <td>Terrye</td>\n",
       "      <td>Balaguer</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>9</td>\n",
       "      <td>3038195150</td>\n",
       "      <td>26321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>332400</td>\n",
       "      <td>Frankie</td>\n",
       "      <td>Bauer</td>\n",
       "      <td>St. Charles</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>5</td>\n",
       "      <td>3223139650</td>\n",
       "      <td>3272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>332401</td>\n",
       "      <td>Stephannie</td>\n",
       "      <td>Iimura</td>\n",
       "      <td>Urbandale</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>1</td>\n",
       "      <td>6410847317</td>\n",
       "      <td>958.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>332500</td>\n",
       "      <td>Honoria</td>\n",
       "      <td>Stathakis</td>\n",
       "      <td>Lawrence</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>4</td>\n",
       "      <td>2549667178</td>\n",
       "      <td>23336.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>332501</td>\n",
       "      <td>Verene</td>\n",
       "      <td>Waternaux</td>\n",
       "      <td>Norwich</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>3</td>\n",
       "      <td>6073396678</td>\n",
       "      <td>2376.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>332600</td>\n",
       "      <td>Callida</td>\n",
       "      <td>Zagaeski</td>\n",
       "      <td>Joliet</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>8</td>\n",
       "      <td>3342089665</td>\n",
       "      <td>9556.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>332601</td>\n",
       "      <td>Remy</td>\n",
       "      <td>Lees</td>\n",
       "      <td>Campbell</td>\n",
       "      <td>California</td>\n",
       "      <td>3</td>\n",
       "      <td>5775942486</td>\n",
       "      <td>8700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>332700</td>\n",
       "      <td>Vivian</td>\n",
       "      <td>Groden</td>\n",
       "      <td>Shoreline</td>\n",
       "      <td>Washington</td>\n",
       "      <td>2</td>\n",
       "      <td>6159990850</td>\n",
       "      <td>11679.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>332701</td>\n",
       "      <td>Jill</td>\n",
       "      <td>Tuchman</td>\n",
       "      <td>Parma</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>5</td>\n",
       "      <td>5304125433</td>\n",
       "      <td>3027.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>332800</td>\n",
       "      <td>Issi</td>\n",
       "      <td>Curzi</td>\n",
       "      <td>North Las Vegas</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>0</td>\n",
       "      <td>6751330061</td>\n",
       "      <td>1181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>332801</td>\n",
       "      <td>Beverly</td>\n",
       "      <td>Poskanzer</td>\n",
       "      <td>Merced</td>\n",
       "      <td>California</td>\n",
       "      <td>6</td>\n",
       "      <td>4006793184</td>\n",
       "      <td>3683.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>332900</td>\n",
       "      <td>Keriann</td>\n",
       "      <td>Angelini</td>\n",
       "      <td>Logan</td>\n",
       "      <td>Utah</td>\n",
       "      <td>5</td>\n",
       "      <td>3767824057</td>\n",
       "      <td>9516.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>332901</td>\n",
       "      <td>Minnie</td>\n",
       "      <td>Samonides</td>\n",
       "      <td>West Valley City</td>\n",
       "      <td>Utah</td>\n",
       "      <td>0</td>\n",
       "      <td>5753224871</td>\n",
       "      <td>657.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>333000</td>\n",
       "      <td>Nanice</td>\n",
       "      <td>Memoli</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>California</td>\n",
       "      <td>8</td>\n",
       "      <td>2629861751</td>\n",
       "      <td>20748.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>333001</td>\n",
       "      <td>Giralda</td>\n",
       "      <td>Vegh</td>\n",
       "      <td>Pensacola</td>\n",
       "      <td>Florida</td>\n",
       "      <td>4</td>\n",
       "      <td>3039492308</td>\n",
       "      <td>12442.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>333100</td>\n",
       "      <td>Kerrie</td>\n",
       "      <td>Wittman</td>\n",
       "      <td>Mission Viejo</td>\n",
       "      <td>California</td>\n",
       "      <td>8</td>\n",
       "      <td>4032658178</td>\n",
       "      <td>11240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>333101</td>\n",
       "      <td>Doris</td>\n",
       "      <td>Lillvik</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>Texas</td>\n",
       "      <td>4</td>\n",
       "      <td>4131221589</td>\n",
       "      <td>6613.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>333200</td>\n",
       "      <td>Philomena</td>\n",
       "      <td>Westerman</td>\n",
       "      <td>Renton</td>\n",
       "      <td>Washington</td>\n",
       "      <td>9</td>\n",
       "      <td>5184982798</td>\n",
       "      <td>104364.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>333201</td>\n",
       "      <td>Bessie</td>\n",
       "      <td>Banzett</td>\n",
       "      <td>Dunwoody</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>8</td>\n",
       "      <td>5723134701</td>\n",
       "      <td>35521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8559</th>\n",
       "      <td>340300</td>\n",
       "      <td>Bambie</td>\n",
       "      <td>Gedaminsky</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>9</td>\n",
       "      <td>6313330399</td>\n",
       "      <td>28693.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8560</th>\n",
       "      <td>340301</td>\n",
       "      <td>Ailey</td>\n",
       "      <td>Gollis</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>6</td>\n",
       "      <td>5279359303</td>\n",
       "      <td>14190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8659</th>\n",
       "      <td>340400</td>\n",
       "      <td>Elisabetta</td>\n",
       "      <td>Sateriale</td>\n",
       "      <td>Sioux City</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>6</td>\n",
       "      <td>2751840192</td>\n",
       "      <td>88665.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8660</th>\n",
       "      <td>340401</td>\n",
       "      <td>Jessi</td>\n",
       "      <td>Christenson</td>\n",
       "      <td>Janesville</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>3</td>\n",
       "      <td>4909215149</td>\n",
       "      <td>4911.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>340500</td>\n",
       "      <td>Jesselyn</td>\n",
       "      <td>Akiba</td>\n",
       "      <td>Athens-Clarke County</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>9</td>\n",
       "      <td>4085521499</td>\n",
       "      <td>24194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8760</th>\n",
       "      <td>340501</td>\n",
       "      <td>Freddy</td>\n",
       "      <td>Churchill</td>\n",
       "      <td>Meridian</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>2</td>\n",
       "      <td>2661206480</td>\n",
       "      <td>27988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8859</th>\n",
       "      <td>340600</td>\n",
       "      <td>Ettie</td>\n",
       "      <td>Thwing</td>\n",
       "      <td>Wilmington</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>1</td>\n",
       "      <td>4867599450</td>\n",
       "      <td>7793.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8860</th>\n",
       "      <td>340601</td>\n",
       "      <td>Cathyleen</td>\n",
       "      <td>Meserve</td>\n",
       "      <td>McKinney</td>\n",
       "      <td>Texas</td>\n",
       "      <td>8</td>\n",
       "      <td>3529726315</td>\n",
       "      <td>20465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8959</th>\n",
       "      <td>340700</td>\n",
       "      <td>Leisha</td>\n",
       "      <td>Corsetti</td>\n",
       "      <td>Napa</td>\n",
       "      <td>California</td>\n",
       "      <td>0</td>\n",
       "      <td>4340847588</td>\n",
       "      <td>35740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8960</th>\n",
       "      <td>340701</td>\n",
       "      <td>Natka</td>\n",
       "      <td>Ginsberg</td>\n",
       "      <td>Daytona Beach</td>\n",
       "      <td>Florida</td>\n",
       "      <td>9</td>\n",
       "      <td>3293300281</td>\n",
       "      <td>62961.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9059</th>\n",
       "      <td>340800</td>\n",
       "      <td>Cristabel</td>\n",
       "      <td>Brecht</td>\n",
       "      <td>North Port</td>\n",
       "      <td>Florida</td>\n",
       "      <td>7</td>\n",
       "      <td>3560335302</td>\n",
       "      <td>17555.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9060</th>\n",
       "      <td>340801</td>\n",
       "      <td>Nananne</td>\n",
       "      <td>O'hare</td>\n",
       "      <td>Concord</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>2</td>\n",
       "      <td>3517741109</td>\n",
       "      <td>3299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9159</th>\n",
       "      <td>340900</td>\n",
       "      <td>Lida</td>\n",
       "      <td>Forsythe</td>\n",
       "      <td>Hammond</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>3</td>\n",
       "      <td>5780140038</td>\n",
       "      <td>19326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9160</th>\n",
       "      <td>340901</td>\n",
       "      <td>Beckie</td>\n",
       "      <td>Theriault</td>\n",
       "      <td>Pomona</td>\n",
       "      <td>California</td>\n",
       "      <td>0</td>\n",
       "      <td>2717417891</td>\n",
       "      <td>7464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9259</th>\n",
       "      <td>341000</td>\n",
       "      <td>Brigida</td>\n",
       "      <td>Lanham</td>\n",
       "      <td>Compton</td>\n",
       "      <td>California</td>\n",
       "      <td>0</td>\n",
       "      <td>3603072193</td>\n",
       "      <td>10185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9260</th>\n",
       "      <td>341001</td>\n",
       "      <td>Mame</td>\n",
       "      <td>Yarden</td>\n",
       "      <td>Oak Park</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>0</td>\n",
       "      <td>5279159866</td>\n",
       "      <td>721.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9359</th>\n",
       "      <td>341100</td>\n",
       "      <td>Alvera</td>\n",
       "      <td>Angus</td>\n",
       "      <td>Utica</td>\n",
       "      <td>New York</td>\n",
       "      <td>3</td>\n",
       "      <td>3249316346</td>\n",
       "      <td>5887.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9360</th>\n",
       "      <td>341101</td>\n",
       "      <td>Cristi</td>\n",
       "      <td>Rahilly</td>\n",
       "      <td>Greenacres</td>\n",
       "      <td>Florida</td>\n",
       "      <td>5</td>\n",
       "      <td>3601490110</td>\n",
       "      <td>124419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9459</th>\n",
       "      <td>341200</td>\n",
       "      <td>Loralie</td>\n",
       "      <td>Jong</td>\n",
       "      <td>Prescott Valley</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>2</td>\n",
       "      <td>6007850562</td>\n",
       "      <td>38569.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9460</th>\n",
       "      <td>341201</td>\n",
       "      <td>Tessa</td>\n",
       "      <td>Sherwin</td>\n",
       "      <td>Lancaster</td>\n",
       "      <td>Texas</td>\n",
       "      <td>1</td>\n",
       "      <td>6295228981</td>\n",
       "      <td>2380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9559</th>\n",
       "      <td>341300</td>\n",
       "      <td>Ivie</td>\n",
       "      <td>Grossi</td>\n",
       "      <td>Duluth</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>2</td>\n",
       "      <td>2490085632</td>\n",
       "      <td>4734.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9560</th>\n",
       "      <td>341301</td>\n",
       "      <td>Shelagh</td>\n",
       "      <td>Taveras</td>\n",
       "      <td>Stillwater</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>5</td>\n",
       "      <td>4761314473</td>\n",
       "      <td>21188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9659</th>\n",
       "      <td>341400</td>\n",
       "      <td>Corrie</td>\n",
       "      <td>Pennazza</td>\n",
       "      <td>Huntington Park</td>\n",
       "      <td>California</td>\n",
       "      <td>4</td>\n",
       "      <td>4872960056</td>\n",
       "      <td>30595.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9660</th>\n",
       "      <td>341401</td>\n",
       "      <td>Letisha</td>\n",
       "      <td>Lawoko</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>3</td>\n",
       "      <td>6606248558</td>\n",
       "      <td>17769.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9759</th>\n",
       "      <td>341500</td>\n",
       "      <td>Nicole</td>\n",
       "      <td>Auden</td>\n",
       "      <td>Belleville</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>9</td>\n",
       "      <td>5226942767</td>\n",
       "      <td>76409.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9760</th>\n",
       "      <td>341501</td>\n",
       "      <td>Amii</td>\n",
       "      <td>Quist</td>\n",
       "      <td>Rocklin</td>\n",
       "      <td>California</td>\n",
       "      <td>2</td>\n",
       "      <td>5211751763</td>\n",
       "      <td>7233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9859</th>\n",
       "      <td>341600</td>\n",
       "      <td>Dolley</td>\n",
       "      <td>Gulotta</td>\n",
       "      <td>Woonsocket</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>1</td>\n",
       "      <td>6120247228</td>\n",
       "      <td>7841.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9860</th>\n",
       "      <td>341601</td>\n",
       "      <td>Mari</td>\n",
       "      <td>Tivegna</td>\n",
       "      <td>Roseville</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>1</td>\n",
       "      <td>6627419753</td>\n",
       "      <td>7690.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9959</th>\n",
       "      <td>341700</td>\n",
       "      <td>Ailene</td>\n",
       "      <td>Kafadar</td>\n",
       "      <td>Allen</td>\n",
       "      <td>Texas</td>\n",
       "      <td>5</td>\n",
       "      <td>5957884302</td>\n",
       "      <td>11714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9960</th>\n",
       "      <td>341701</td>\n",
       "      <td>Hilary</td>\n",
       "      <td>Singsen</td>\n",
       "      <td>Washington</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>1</td>\n",
       "      <td>4401697955</td>\n",
       "      <td>7066.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cust_id    first_name    last_name                  city  \\\n",
       "59     331800        Davida    Cedarbaum                Normal   \n",
       "60     331801           Kym       Hottle           Brownsville   \n",
       "159    331900  Barbara-Anne       Troisi          Baldwin Park   \n",
       "160    331901     Charlotte         Drew         Moreno Valley   \n",
       "259    332000          Sada   Abdulrazak                Carson   \n",
       "260    332001          Cleo       Soares             Mansfield   \n",
       "359    332100        Glenda    Mcchesney              Lakewood   \n",
       "360    332101      Antonina  Ross-Degnan              Torrance   \n",
       "459    332200          Katy    Maclaurin           Victorville   \n",
       "460    332201         Liesa     Moeykens                Peoria   \n",
       "559    332300     Magdalena      Chehabi           Federal Way   \n",
       "560    332301        Terrye     Balaguer               Raleigh   \n",
       "659    332400       Frankie        Bauer           St. Charles   \n",
       "660    332401    Stephannie       Iimura             Urbandale   \n",
       "759    332500       Honoria    Stathakis              Lawrence   \n",
       "760    332501        Verene    Waternaux               Norwich   \n",
       "859    332600       Callida     Zagaeski                Joliet   \n",
       "860    332601          Remy         Lees              Campbell   \n",
       "959    332700        Vivian       Groden             Shoreline   \n",
       "960    332701          Jill      Tuchman                 Parma   \n",
       "1059   332800          Issi        Curzi       North Las Vegas   \n",
       "1060   332801       Beverly    Poskanzer                Merced   \n",
       "1159   332900       Keriann     Angelini                 Logan   \n",
       "1160   332901        Minnie    Samonides      West Valley City   \n",
       "1259   333000        Nanice       Memoli              San Jose   \n",
       "1260   333001       Giralda         Vegh             Pensacola   \n",
       "1359   333100        Kerrie      Wittman         Mission Viejo   \n",
       "1360   333101         Doris      Lillvik               Abilene   \n",
       "1459   333200     Philomena    Westerman                Renton   \n",
       "1460   333201        Bessie      Banzett              Dunwoody   \n",
       "...       ...           ...          ...                   ...   \n",
       "8559   340300        Bambie   Gedaminsky             Las Vegas   \n",
       "8560   340301         Ailey       Gollis                Aurora   \n",
       "8659   340400    Elisabetta    Sateriale            Sioux City   \n",
       "8660   340401         Jessi  Christenson            Janesville   \n",
       "8759   340500      Jesselyn        Akiba  Athens-Clarke County   \n",
       "8760   340501        Freddy    Churchill              Meridian   \n",
       "8859   340600         Ettie       Thwing            Wilmington   \n",
       "8860   340601     Cathyleen      Meserve              McKinney   \n",
       "8959   340700        Leisha     Corsetti                  Napa   \n",
       "8960   340701         Natka     Ginsberg         Daytona Beach   \n",
       "9059   340800     Cristabel       Brecht            North Port   \n",
       "9060   340801       Nananne       O'hare               Concord   \n",
       "9159   340900          Lida     Forsythe               Hammond   \n",
       "9160   340901        Beckie    Theriault                Pomona   \n",
       "9259   341000       Brigida       Lanham               Compton   \n",
       "9260   341001          Mame       Yarden              Oak Park   \n",
       "9359   341100        Alvera        Angus                 Utica   \n",
       "9360   341101        Cristi      Rahilly            Greenacres   \n",
       "9459   341200       Loralie         Jong       Prescott Valley   \n",
       "9460   341201         Tessa      Sherwin             Lancaster   \n",
       "9559   341300          Ivie       Grossi                Duluth   \n",
       "9560   341301       Shelagh      Taveras            Stillwater   \n",
       "9659   341400        Corrie     Pennazza       Huntington Park   \n",
       "9660   341401       Letisha       Lawoko               Chicago   \n",
       "9759   341500        Nicole        Auden            Belleville   \n",
       "9760   341501          Amii        Quist               Rocklin   \n",
       "9859   341600        Dolley      Gulotta            Woonsocket   \n",
       "9860   341601          Mari      Tivegna             Roseville   \n",
       "9959   341700        Ailene      Kafadar                 Allen   \n",
       "9960   341701        Hilary      Singsen            Washington   \n",
       "\n",
       "                     state  tier       phone     sales  \n",
       "59                Illinois     4  5689070376   22482.0  \n",
       "60                   Texas     4  5273220578    3371.0  \n",
       "159             California     9  4102242190   18483.0  \n",
       "160             California     7  2968087426    8465.0  \n",
       "259             California     4  6520553137    8133.0  \n",
       "260                   Ohio     8  5730383961  290471.0  \n",
       "359                   Ohio     2  4833862965   14544.0  \n",
       "360             California     7  3611540956   24146.0  \n",
       "459             California     2  5961824651   85302.0  \n",
       "460               Illinois     3  2350974211    4406.0  \n",
       "559             Washington     8  6811170301    9055.0  \n",
       "560         North Carolina     9  3038195150   26321.0  \n",
       "659               Missouri     5  3223139650    3272.0  \n",
       "660                   Iowa     1  6410847317     958.0  \n",
       "759                Indiana     4  2549667178   23336.0  \n",
       "760            Connecticut     3  6073396678    2376.0  \n",
       "859               Illinois     8  3342089665    9556.0  \n",
       "860             California     3  5775942486    8700.0  \n",
       "959             Washington     2  6159990850   11679.0  \n",
       "960                   Ohio     5  5304125433    3027.0  \n",
       "1059                Nevada     0  6751330061    1181.0  \n",
       "1060            California     6  4006793184    3683.0  \n",
       "1159                  Utah     5  3767824057    9516.0  \n",
       "1160                  Utah     0  5753224871     657.0  \n",
       "1259            California     8  2629861751   20748.0  \n",
       "1260               Florida     4  3039492308   12442.0  \n",
       "1359            California     8  4032658178   11240.0  \n",
       "1360                 Texas     4  4131221589    6613.0  \n",
       "1459            Washington     9  5184982798  104364.0  \n",
       "1460               Georgia     8  5723134701   35521.0  \n",
       "...                    ...   ...         ...       ...  \n",
       "8559                Nevada     9  6313330399   28693.0  \n",
       "8560              Illinois     6  5279359303   14190.0  \n",
       "8659                  Iowa     6  2751840192   88665.0  \n",
       "8660             Wisconsin     3  4909215149    4911.0  \n",
       "8759               Georgia     9  4085521499   24194.0  \n",
       "8760           Mississippi     2  2661206480   27988.0  \n",
       "8859              Delaware     1  4867599450    7793.0  \n",
       "8860                 Texas     8  3529726315   20465.0  \n",
       "8959            California     0  4340847588   35740.0  \n",
       "8960               Florida     9  3293300281   62961.0  \n",
       "9059               Florida     7  3560335302   17555.0  \n",
       "9060         New Hampshire     2  3517741109    3299.0  \n",
       "9159               Indiana     3  5780140038   19326.0  \n",
       "9160            California     0  2717417891    7464.0  \n",
       "9259            California     0  3603072193   10185.0  \n",
       "9260              Illinois     0  5279159866     721.0  \n",
       "9359              New York     3  3249316346    5887.0  \n",
       "9360               Florida     5  3601490110  124419.0  \n",
       "9459               Arizona     2  6007850562   38569.0  \n",
       "9460                 Texas     1  6295228981    2380.0  \n",
       "9559             Minnesota     2  2490085632    4734.0  \n",
       "9560              Oklahoma     5  4761314473   21188.0  \n",
       "9659            California     4  4872960056   30595.0  \n",
       "9660              Illinois     3  6606248558   17769.0  \n",
       "9759              Illinois     9  5226942767   76409.0  \n",
       "9760            California     2  5211751763    7233.0  \n",
       "9859          Rhode Island     1  6120247228    7841.0  \n",
       "9860              Michigan     1  6627419753    7690.0  \n",
       "9959                 Texas     5  5957884302   11714.0  \n",
       "9960  District of Columbia     1  4401697955    7066.0  \n",
       "\n",
       "[200 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cust17 = customer[ customer[\"cust_id\"] % 100 < 2 ]\n",
    "cust17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to write this back to our DB, the easiest way is to create an \"sqlalchemy engine\" that points to our postgresql and has the approrpiate credentials built-in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(postgresql://user1:***@localhost:5432/postgres)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://user1:pwd1@localhost:5432/postgres')\n",
    "engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An then simply use the `.to_sql` method on our dataframe of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 ms Â± 0 ns per loop (mean Â± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r1 -n1\n",
    "cust17.to_sql( 'cust_procesado1', \n",
    "               engine, if_exists = 'replace',\n",
    "               index=False)  # 'cust17' is going to be the name of the new table in the db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cust_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>tier</th>\n",
       "      <th>phone</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>331800</td>\n",
       "      <td>Davida</td>\n",
       "      <td>Cedarbaum</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>4</td>\n",
       "      <td>5689070376</td>\n",
       "      <td>22482.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>331801</td>\n",
       "      <td>Kym</td>\n",
       "      <td>Hottle</td>\n",
       "      <td>Brownsville</td>\n",
       "      <td>Texas</td>\n",
       "      <td>4</td>\n",
       "      <td>5273220578</td>\n",
       "      <td>3371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>331900</td>\n",
       "      <td>Barbara-Anne</td>\n",
       "      <td>Troisi</td>\n",
       "      <td>Baldwin Park</td>\n",
       "      <td>California</td>\n",
       "      <td>9</td>\n",
       "      <td>4102242190</td>\n",
       "      <td>18483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>331901</td>\n",
       "      <td>Charlotte</td>\n",
       "      <td>Drew</td>\n",
       "      <td>Moreno Valley</td>\n",
       "      <td>California</td>\n",
       "      <td>7</td>\n",
       "      <td>2968087426</td>\n",
       "      <td>8465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>332000</td>\n",
       "      <td>Sada</td>\n",
       "      <td>Abdulrazak</td>\n",
       "      <td>Carson</td>\n",
       "      <td>California</td>\n",
       "      <td>4</td>\n",
       "      <td>6520553137</td>\n",
       "      <td>8133.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>332001</td>\n",
       "      <td>Cleo</td>\n",
       "      <td>Soares</td>\n",
       "      <td>Mansfield</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>8</td>\n",
       "      <td>5730383961</td>\n",
       "      <td>290471.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>332100</td>\n",
       "      <td>Glenda</td>\n",
       "      <td>Mcchesney</td>\n",
       "      <td>Lakewood</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>2</td>\n",
       "      <td>4833862965</td>\n",
       "      <td>14544.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>332101</td>\n",
       "      <td>Antonina</td>\n",
       "      <td>Ross-Degnan</td>\n",
       "      <td>Torrance</td>\n",
       "      <td>California</td>\n",
       "      <td>7</td>\n",
       "      <td>3611540956</td>\n",
       "      <td>24146.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>332200</td>\n",
       "      <td>Katy</td>\n",
       "      <td>Maclaurin</td>\n",
       "      <td>Victorville</td>\n",
       "      <td>California</td>\n",
       "      <td>2</td>\n",
       "      <td>5961824651</td>\n",
       "      <td>85302.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>332201</td>\n",
       "      <td>Liesa</td>\n",
       "      <td>Moeykens</td>\n",
       "      <td>Peoria</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>3</td>\n",
       "      <td>2350974211</td>\n",
       "      <td>4406.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>332300</td>\n",
       "      <td>Magdalena</td>\n",
       "      <td>Chehabi</td>\n",
       "      <td>Federal Way</td>\n",
       "      <td>Washington</td>\n",
       "      <td>8</td>\n",
       "      <td>6811170301</td>\n",
       "      <td>9055.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>332301</td>\n",
       "      <td>Terrye</td>\n",
       "      <td>Balaguer</td>\n",
       "      <td>Raleigh</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>9</td>\n",
       "      <td>3038195150</td>\n",
       "      <td>26321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>332400</td>\n",
       "      <td>Frankie</td>\n",
       "      <td>Bauer</td>\n",
       "      <td>St. Charles</td>\n",
       "      <td>Missouri</td>\n",
       "      <td>5</td>\n",
       "      <td>3223139650</td>\n",
       "      <td>3272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>332401</td>\n",
       "      <td>Stephannie</td>\n",
       "      <td>Iimura</td>\n",
       "      <td>Urbandale</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>1</td>\n",
       "      <td>6410847317</td>\n",
       "      <td>958.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>332500</td>\n",
       "      <td>Honoria</td>\n",
       "      <td>Stathakis</td>\n",
       "      <td>Lawrence</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>4</td>\n",
       "      <td>2549667178</td>\n",
       "      <td>23336.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>332501</td>\n",
       "      <td>Verene</td>\n",
       "      <td>Waternaux</td>\n",
       "      <td>Norwich</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>3</td>\n",
       "      <td>6073396678</td>\n",
       "      <td>2376.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>332600</td>\n",
       "      <td>Callida</td>\n",
       "      <td>Zagaeski</td>\n",
       "      <td>Joliet</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>8</td>\n",
       "      <td>3342089665</td>\n",
       "      <td>9556.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>332601</td>\n",
       "      <td>Remy</td>\n",
       "      <td>Lees</td>\n",
       "      <td>Campbell</td>\n",
       "      <td>California</td>\n",
       "      <td>3</td>\n",
       "      <td>5775942486</td>\n",
       "      <td>8700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>332700</td>\n",
       "      <td>Vivian</td>\n",
       "      <td>Groden</td>\n",
       "      <td>Shoreline</td>\n",
       "      <td>Washington</td>\n",
       "      <td>2</td>\n",
       "      <td>6159990850</td>\n",
       "      <td>11679.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>332701</td>\n",
       "      <td>Jill</td>\n",
       "      <td>Tuchman</td>\n",
       "      <td>Parma</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>5</td>\n",
       "      <td>5304125433</td>\n",
       "      <td>3027.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>332800</td>\n",
       "      <td>Issi</td>\n",
       "      <td>Curzi</td>\n",
       "      <td>North Las Vegas</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>0</td>\n",
       "      <td>6751330061</td>\n",
       "      <td>1181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>332801</td>\n",
       "      <td>Beverly</td>\n",
       "      <td>Poskanzer</td>\n",
       "      <td>Merced</td>\n",
       "      <td>California</td>\n",
       "      <td>6</td>\n",
       "      <td>4006793184</td>\n",
       "      <td>3683.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>332900</td>\n",
       "      <td>Keriann</td>\n",
       "      <td>Angelini</td>\n",
       "      <td>Logan</td>\n",
       "      <td>Utah</td>\n",
       "      <td>5</td>\n",
       "      <td>3767824057</td>\n",
       "      <td>9516.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>332901</td>\n",
       "      <td>Minnie</td>\n",
       "      <td>Samonides</td>\n",
       "      <td>West Valley City</td>\n",
       "      <td>Utah</td>\n",
       "      <td>0</td>\n",
       "      <td>5753224871</td>\n",
       "      <td>657.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>333000</td>\n",
       "      <td>Nanice</td>\n",
       "      <td>Memoli</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>California</td>\n",
       "      <td>8</td>\n",
       "      <td>2629861751</td>\n",
       "      <td>20748.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>333001</td>\n",
       "      <td>Giralda</td>\n",
       "      <td>Vegh</td>\n",
       "      <td>Pensacola</td>\n",
       "      <td>Florida</td>\n",
       "      <td>4</td>\n",
       "      <td>3039492308</td>\n",
       "      <td>12442.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>333100</td>\n",
       "      <td>Kerrie</td>\n",
       "      <td>Wittman</td>\n",
       "      <td>Mission Viejo</td>\n",
       "      <td>California</td>\n",
       "      <td>8</td>\n",
       "      <td>4032658178</td>\n",
       "      <td>11240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>333101</td>\n",
       "      <td>Doris</td>\n",
       "      <td>Lillvik</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>Texas</td>\n",
       "      <td>4</td>\n",
       "      <td>4131221589</td>\n",
       "      <td>6613.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>333200</td>\n",
       "      <td>Philomena</td>\n",
       "      <td>Westerman</td>\n",
       "      <td>Renton</td>\n",
       "      <td>Washington</td>\n",
       "      <td>9</td>\n",
       "      <td>5184982798</td>\n",
       "      <td>104364.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>333201</td>\n",
       "      <td>Bessie</td>\n",
       "      <td>Banzett</td>\n",
       "      <td>Dunwoody</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>8</td>\n",
       "      <td>5723134701</td>\n",
       "      <td>35521.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>340300</td>\n",
       "      <td>Bambie</td>\n",
       "      <td>Gedaminsky</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>Nevada</td>\n",
       "      <td>9</td>\n",
       "      <td>6313330399</td>\n",
       "      <td>28693.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>340301</td>\n",
       "      <td>Ailey</td>\n",
       "      <td>Gollis</td>\n",
       "      <td>Aurora</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>6</td>\n",
       "      <td>5279359303</td>\n",
       "      <td>14190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>340400</td>\n",
       "      <td>Elisabetta</td>\n",
       "      <td>Sateriale</td>\n",
       "      <td>Sioux City</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>6</td>\n",
       "      <td>2751840192</td>\n",
       "      <td>88665.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>340401</td>\n",
       "      <td>Jessi</td>\n",
       "      <td>Christenson</td>\n",
       "      <td>Janesville</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>3</td>\n",
       "      <td>4909215149</td>\n",
       "      <td>4911.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>340500</td>\n",
       "      <td>Jesselyn</td>\n",
       "      <td>Akiba</td>\n",
       "      <td>Athens-Clarke County</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>9</td>\n",
       "      <td>4085521499</td>\n",
       "      <td>24194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>340501</td>\n",
       "      <td>Freddy</td>\n",
       "      <td>Churchill</td>\n",
       "      <td>Meridian</td>\n",
       "      <td>Mississippi</td>\n",
       "      <td>2</td>\n",
       "      <td>2661206480</td>\n",
       "      <td>27988.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>340600</td>\n",
       "      <td>Ettie</td>\n",
       "      <td>Thwing</td>\n",
       "      <td>Wilmington</td>\n",
       "      <td>Delaware</td>\n",
       "      <td>1</td>\n",
       "      <td>4867599450</td>\n",
       "      <td>7793.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>340601</td>\n",
       "      <td>Cathyleen</td>\n",
       "      <td>Meserve</td>\n",
       "      <td>McKinney</td>\n",
       "      <td>Texas</td>\n",
       "      <td>8</td>\n",
       "      <td>3529726315</td>\n",
       "      <td>20465.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>340700</td>\n",
       "      <td>Leisha</td>\n",
       "      <td>Corsetti</td>\n",
       "      <td>Napa</td>\n",
       "      <td>California</td>\n",
       "      <td>0</td>\n",
       "      <td>4340847588</td>\n",
       "      <td>35740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>340701</td>\n",
       "      <td>Natka</td>\n",
       "      <td>Ginsberg</td>\n",
       "      <td>Daytona Beach</td>\n",
       "      <td>Florida</td>\n",
       "      <td>9</td>\n",
       "      <td>3293300281</td>\n",
       "      <td>62961.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>340800</td>\n",
       "      <td>Cristabel</td>\n",
       "      <td>Brecht</td>\n",
       "      <td>North Port</td>\n",
       "      <td>Florida</td>\n",
       "      <td>7</td>\n",
       "      <td>3560335302</td>\n",
       "      <td>17555.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>340801</td>\n",
       "      <td>Nananne</td>\n",
       "      <td>O'hare</td>\n",
       "      <td>Concord</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>2</td>\n",
       "      <td>3517741109</td>\n",
       "      <td>3299.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>340900</td>\n",
       "      <td>Lida</td>\n",
       "      <td>Forsythe</td>\n",
       "      <td>Hammond</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>3</td>\n",
       "      <td>5780140038</td>\n",
       "      <td>19326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>340901</td>\n",
       "      <td>Beckie</td>\n",
       "      <td>Theriault</td>\n",
       "      <td>Pomona</td>\n",
       "      <td>California</td>\n",
       "      <td>0</td>\n",
       "      <td>2717417891</td>\n",
       "      <td>7464.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>341000</td>\n",
       "      <td>Brigida</td>\n",
       "      <td>Lanham</td>\n",
       "      <td>Compton</td>\n",
       "      <td>California</td>\n",
       "      <td>0</td>\n",
       "      <td>3603072193</td>\n",
       "      <td>10185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>341001</td>\n",
       "      <td>Mame</td>\n",
       "      <td>Yarden</td>\n",
       "      <td>Oak Park</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>0</td>\n",
       "      <td>5279159866</td>\n",
       "      <td>721.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>341100</td>\n",
       "      <td>Alvera</td>\n",
       "      <td>Angus</td>\n",
       "      <td>Utica</td>\n",
       "      <td>New York</td>\n",
       "      <td>3</td>\n",
       "      <td>3249316346</td>\n",
       "      <td>5887.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>341101</td>\n",
       "      <td>Cristi</td>\n",
       "      <td>Rahilly</td>\n",
       "      <td>Greenacres</td>\n",
       "      <td>Florida</td>\n",
       "      <td>5</td>\n",
       "      <td>3601490110</td>\n",
       "      <td>124419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>341200</td>\n",
       "      <td>Loralie</td>\n",
       "      <td>Jong</td>\n",
       "      <td>Prescott Valley</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>2</td>\n",
       "      <td>6007850562</td>\n",
       "      <td>38569.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>341201</td>\n",
       "      <td>Tessa</td>\n",
       "      <td>Sherwin</td>\n",
       "      <td>Lancaster</td>\n",
       "      <td>Texas</td>\n",
       "      <td>1</td>\n",
       "      <td>6295228981</td>\n",
       "      <td>2380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>341300</td>\n",
       "      <td>Ivie</td>\n",
       "      <td>Grossi</td>\n",
       "      <td>Duluth</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>2</td>\n",
       "      <td>2490085632</td>\n",
       "      <td>4734.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>341301</td>\n",
       "      <td>Shelagh</td>\n",
       "      <td>Taveras</td>\n",
       "      <td>Stillwater</td>\n",
       "      <td>Oklahoma</td>\n",
       "      <td>5</td>\n",
       "      <td>4761314473</td>\n",
       "      <td>21188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>341400</td>\n",
       "      <td>Corrie</td>\n",
       "      <td>Pennazza</td>\n",
       "      <td>Huntington Park</td>\n",
       "      <td>California</td>\n",
       "      <td>4</td>\n",
       "      <td>4872960056</td>\n",
       "      <td>30595.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>341401</td>\n",
       "      <td>Letisha</td>\n",
       "      <td>Lawoko</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>3</td>\n",
       "      <td>6606248558</td>\n",
       "      <td>17769.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>341500</td>\n",
       "      <td>Nicole</td>\n",
       "      <td>Auden</td>\n",
       "      <td>Belleville</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>9</td>\n",
       "      <td>5226942767</td>\n",
       "      <td>76409.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>341501</td>\n",
       "      <td>Amii</td>\n",
       "      <td>Quist</td>\n",
       "      <td>Rocklin</td>\n",
       "      <td>California</td>\n",
       "      <td>2</td>\n",
       "      <td>5211751763</td>\n",
       "      <td>7233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>341600</td>\n",
       "      <td>Dolley</td>\n",
       "      <td>Gulotta</td>\n",
       "      <td>Woonsocket</td>\n",
       "      <td>Rhode Island</td>\n",
       "      <td>1</td>\n",
       "      <td>6120247228</td>\n",
       "      <td>7841.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>341601</td>\n",
       "      <td>Mari</td>\n",
       "      <td>Tivegna</td>\n",
       "      <td>Roseville</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>1</td>\n",
       "      <td>6627419753</td>\n",
       "      <td>7690.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>341700</td>\n",
       "      <td>Ailene</td>\n",
       "      <td>Kafadar</td>\n",
       "      <td>Allen</td>\n",
       "      <td>Texas</td>\n",
       "      <td>5</td>\n",
       "      <td>5957884302</td>\n",
       "      <td>11714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>341701</td>\n",
       "      <td>Hilary</td>\n",
       "      <td>Singsen</td>\n",
       "      <td>Washington</td>\n",
       "      <td>District of Columbia</td>\n",
       "      <td>1</td>\n",
       "      <td>4401697955</td>\n",
       "      <td>7066.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     cust_id    first_name    last_name                  city  \\\n",
       "0     331800        Davida    Cedarbaum                Normal   \n",
       "1     331801           Kym       Hottle           Brownsville   \n",
       "2     331900  Barbara-Anne       Troisi          Baldwin Park   \n",
       "3     331901     Charlotte         Drew         Moreno Valley   \n",
       "4     332000          Sada   Abdulrazak                Carson   \n",
       "5     332001          Cleo       Soares             Mansfield   \n",
       "6     332100        Glenda    Mcchesney              Lakewood   \n",
       "7     332101      Antonina  Ross-Degnan              Torrance   \n",
       "8     332200          Katy    Maclaurin           Victorville   \n",
       "9     332201         Liesa     Moeykens                Peoria   \n",
       "10    332300     Magdalena      Chehabi           Federal Way   \n",
       "11    332301        Terrye     Balaguer               Raleigh   \n",
       "12    332400       Frankie        Bauer           St. Charles   \n",
       "13    332401    Stephannie       Iimura             Urbandale   \n",
       "14    332500       Honoria    Stathakis              Lawrence   \n",
       "15    332501        Verene    Waternaux               Norwich   \n",
       "16    332600       Callida     Zagaeski                Joliet   \n",
       "17    332601          Remy         Lees              Campbell   \n",
       "18    332700        Vivian       Groden             Shoreline   \n",
       "19    332701          Jill      Tuchman                 Parma   \n",
       "20    332800          Issi        Curzi       North Las Vegas   \n",
       "21    332801       Beverly    Poskanzer                Merced   \n",
       "22    332900       Keriann     Angelini                 Logan   \n",
       "23    332901        Minnie    Samonides      West Valley City   \n",
       "24    333000        Nanice       Memoli              San Jose   \n",
       "25    333001       Giralda         Vegh             Pensacola   \n",
       "26    333100        Kerrie      Wittman         Mission Viejo   \n",
       "27    333101         Doris      Lillvik               Abilene   \n",
       "28    333200     Philomena    Westerman                Renton   \n",
       "29    333201        Bessie      Banzett              Dunwoody   \n",
       "..       ...           ...          ...                   ...   \n",
       "170   340300        Bambie   Gedaminsky             Las Vegas   \n",
       "171   340301         Ailey       Gollis                Aurora   \n",
       "172   340400    Elisabetta    Sateriale            Sioux City   \n",
       "173   340401         Jessi  Christenson            Janesville   \n",
       "174   340500      Jesselyn        Akiba  Athens-Clarke County   \n",
       "175   340501        Freddy    Churchill              Meridian   \n",
       "176   340600         Ettie       Thwing            Wilmington   \n",
       "177   340601     Cathyleen      Meserve              McKinney   \n",
       "178   340700        Leisha     Corsetti                  Napa   \n",
       "179   340701         Natka     Ginsberg         Daytona Beach   \n",
       "180   340800     Cristabel       Brecht            North Port   \n",
       "181   340801       Nananne       O'hare               Concord   \n",
       "182   340900          Lida     Forsythe               Hammond   \n",
       "183   340901        Beckie    Theriault                Pomona   \n",
       "184   341000       Brigida       Lanham               Compton   \n",
       "185   341001          Mame       Yarden              Oak Park   \n",
       "186   341100        Alvera        Angus                 Utica   \n",
       "187   341101        Cristi      Rahilly            Greenacres   \n",
       "188   341200       Loralie         Jong       Prescott Valley   \n",
       "189   341201         Tessa      Sherwin             Lancaster   \n",
       "190   341300          Ivie       Grossi                Duluth   \n",
       "191   341301       Shelagh      Taveras            Stillwater   \n",
       "192   341400        Corrie     Pennazza       Huntington Park   \n",
       "193   341401       Letisha       Lawoko               Chicago   \n",
       "194   341500        Nicole        Auden            Belleville   \n",
       "195   341501          Amii        Quist               Rocklin   \n",
       "196   341600        Dolley      Gulotta            Woonsocket   \n",
       "197   341601          Mari      Tivegna             Roseville   \n",
       "198   341700        Ailene      Kafadar                 Allen   \n",
       "199   341701        Hilary      Singsen            Washington   \n",
       "\n",
       "                    state  tier       phone     sales  \n",
       "0                Illinois     4  5689070376   22482.0  \n",
       "1                   Texas     4  5273220578    3371.0  \n",
       "2              California     9  4102242190   18483.0  \n",
       "3              California     7  2968087426    8465.0  \n",
       "4              California     4  6520553137    8133.0  \n",
       "5                    Ohio     8  5730383961  290471.0  \n",
       "6                    Ohio     2  4833862965   14544.0  \n",
       "7              California     7  3611540956   24146.0  \n",
       "8              California     2  5961824651   85302.0  \n",
       "9                Illinois     3  2350974211    4406.0  \n",
       "10             Washington     8  6811170301    9055.0  \n",
       "11         North Carolina     9  3038195150   26321.0  \n",
       "12               Missouri     5  3223139650    3272.0  \n",
       "13                   Iowa     1  6410847317     958.0  \n",
       "14                Indiana     4  2549667178   23336.0  \n",
       "15            Connecticut     3  6073396678    2376.0  \n",
       "16               Illinois     8  3342089665    9556.0  \n",
       "17             California     3  5775942486    8700.0  \n",
       "18             Washington     2  6159990850   11679.0  \n",
       "19                   Ohio     5  5304125433    3027.0  \n",
       "20                 Nevada     0  6751330061    1181.0  \n",
       "21             California     6  4006793184    3683.0  \n",
       "22                   Utah     5  3767824057    9516.0  \n",
       "23                   Utah     0  5753224871     657.0  \n",
       "24             California     8  2629861751   20748.0  \n",
       "25                Florida     4  3039492308   12442.0  \n",
       "26             California     8  4032658178   11240.0  \n",
       "27                  Texas     4  4131221589    6613.0  \n",
       "28             Washington     9  5184982798  104364.0  \n",
       "29                Georgia     8  5723134701   35521.0  \n",
       "..                    ...   ...         ...       ...  \n",
       "170                Nevada     9  6313330399   28693.0  \n",
       "171              Illinois     6  5279359303   14190.0  \n",
       "172                  Iowa     6  2751840192   88665.0  \n",
       "173             Wisconsin     3  4909215149    4911.0  \n",
       "174               Georgia     9  4085521499   24194.0  \n",
       "175           Mississippi     2  2661206480   27988.0  \n",
       "176              Delaware     1  4867599450    7793.0  \n",
       "177                 Texas     8  3529726315   20465.0  \n",
       "178            California     0  4340847588   35740.0  \n",
       "179               Florida     9  3293300281   62961.0  \n",
       "180               Florida     7  3560335302   17555.0  \n",
       "181         New Hampshire     2  3517741109    3299.0  \n",
       "182               Indiana     3  5780140038   19326.0  \n",
       "183            California     0  2717417891    7464.0  \n",
       "184            California     0  3603072193   10185.0  \n",
       "185              Illinois     0  5279159866     721.0  \n",
       "186              New York     3  3249316346    5887.0  \n",
       "187               Florida     5  3601490110  124419.0  \n",
       "188               Arizona     2  6007850562   38569.0  \n",
       "189                 Texas     1  6295228981    2380.0  \n",
       "190             Minnesota     2  2490085632    4734.0  \n",
       "191              Oklahoma     5  4761314473   21188.0  \n",
       "192            California     4  4872960056   30595.0  \n",
       "193              Illinois     3  6606248558   17769.0  \n",
       "194              Illinois     9  5226942767   76409.0  \n",
       "195            California     2  5211751763    7233.0  \n",
       "196          Rhode Island     1  6120247228    7841.0  \n",
       "197              Michigan     1  6627419753    7690.0  \n",
       "198                 Texas     5  5957884302   11714.0  \n",
       "199  District of Columbia     1  4401697955    7066.0  \n",
       "\n",
       "[200 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql( \"select * from cust_procesado1\", conn )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method to_sql in module pandas.core.generic:\n",
      "\n",
      "to_sql(name, con, schema=None, if_exists='fail', index=True, index_label=None, chunksize=None, dtype=None) method of pandas.core.frame.DataFrame instance\n",
      "    Write records stored in a DataFrame to a SQL database.\n",
      "    \n",
      "    Databases supported by SQLAlchemy [1]_ are supported. Tables can be\n",
      "    newly created, appended to, or overwritten.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    name : string\n",
      "        Name of SQL table.\n",
      "    con : sqlalchemy.engine.Engine or sqlite3.Connection\n",
      "        Using SQLAlchemy makes it possible to use any DB supported by that\n",
      "        library. Legacy support is provided for sqlite3.Connection objects.\n",
      "    schema : string, optional\n",
      "        Specify the schema (if database flavor supports this). If None, use\n",
      "        default schema.\n",
      "    if_exists : {'fail', 'replace', 'append'}, default 'fail'\n",
      "        How to behave if the table already exists.\n",
      "    \n",
      "        * fail: Raise a ValueError.\n",
      "        * replace: Drop the table before inserting new values.\n",
      "        * append: Insert new values to the existing table.\n",
      "    \n",
      "    index : boolean, default True\n",
      "        Write DataFrame index as a column. Uses `index_label` as the column\n",
      "        name in the table.\n",
      "    index_label : string or sequence, default None\n",
      "        Column label for index column(s). If None is given (default) and\n",
      "        `index` is True, then the index names are used.\n",
      "        A sequence should be given if the DataFrame uses MultiIndex.\n",
      "    chunksize : int, optional\n",
      "        Rows will be written in batches of this size at a time. By default,\n",
      "        all rows will be written at once.\n",
      "    dtype : dict, optional\n",
      "        Specifying the datatype for columns. The keys should be the column\n",
      "        names and the values should be the SQLAlchemy types or strings for\n",
      "        the sqlite3 legacy mode.\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    ValueError\n",
      "        When the table already exists and `if_exists` is 'fail' (the\n",
      "        default).\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    pandas.read_sql : read a DataFrame from a table\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] http://docs.sqlalchemy.org\n",
      "    .. [2] https://www.python.org/dev/peps/pep-0249/\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    \n",
      "    Create an in-memory SQLite database.\n",
      "    \n",
      "    >>> from sqlalchemy import create_engine\n",
      "    >>> engine = create_engine('sqlite://', echo=False)\n",
      "    \n",
      "    Create a table from scratch with 3 rows.\n",
      "    \n",
      "    >>> df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})\n",
      "    >>> df\n",
      "         name\n",
      "    0  User 1\n",
      "    1  User 2\n",
      "    2  User 3\n",
      "    \n",
      "    >>> df.to_sql('users', con=engine)\n",
      "    >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      "    [(0, 'User 1'), (1, 'User 2'), (2, 'User 3')]\n",
      "    \n",
      "    >>> df1 = pd.DataFrame({'name' : ['User 4', 'User 5']})\n",
      "    >>> df1.to_sql('users', con=engine, if_exists='append')\n",
      "    >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      "    [(0, 'User 1'), (1, 'User 2'), (2, 'User 3'),\n",
      "     (0, 'User 4'), (1, 'User 5')]\n",
      "    \n",
      "    Overwrite the table with just ``df1``.\n",
      "    \n",
      "    >>> df1.to_sql('users', con=engine, if_exists='replace',\n",
      "    ...            index_label='id')\n",
      "    >>> engine.execute(\"SELECT * FROM users\").fetchall()\n",
      "    [(0, 'User 4'), (1, 'User 5')]\n",
      "    \n",
      "    Specify the dtype (especially useful for integers with missing values).\n",
      "    Notice that while pandas is forced to store the data as floating point,\n",
      "    the database supports nullable integers. When fetching the data with\n",
      "    Python, we get back integer scalars.\n",
      "    \n",
      "    >>> df = pd.DataFrame({\"A\": [1, None, 2]})\n",
      "    >>> df\n",
      "         A\n",
      "    0  1.0\n",
      "    1  NaN\n",
      "    2  2.0\n",
      "    \n",
      "    >>> from sqlalchemy.types import Integer\n",
      "    >>> df.to_sql('integers', con=engine, index=False,\n",
      "    ...           dtype={\"A\": Integer()})\n",
      "    \n",
      "    >>> engine.execute(\"SELECT * FROM integers\").fetchall()\n",
      "    [(1,), (None,), (2,)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help( cust17.to_sql ) # figure out how to get rid of the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"advanced\"></div>\n",
    "## Section 2: Some advanced data operations\n",
    "\n",
    "In this data workshop, we will see some advanced data operatorions using Pandas such as merging (joining), accessing data through an index, and re-arranging data. \n",
    "\n",
    "Let's load our 'House Prices' dataset that we are familiar with from the previous workshop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_df = pd.read_csv( DATA_DIR + \"house_prices_and_characteristics.csv\" ).drop( \"Id\", axis=1).sort_values('SalePrice')\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And now for the actual aggregation exercises, in which the output data does matter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"indexing\"></div>\n",
    "## Indexing\n",
    "\n",
    "An **index** in a data frame is a set of values that play essentially the same role as the keys in a dictionary. An index is usually composed of integers, strings or tuples. To each value of the index, there is an associated row or, possibly, a *set of rows* in the data frame. \n",
    "\n",
    "Further, accessing that row or set of rows is an efficient (O(1)) operation that **does not** *require to scan* the whole data set. \n",
    "\n",
    "It's important to note that the index is *not considered* a column in the dataset as such. It's in a different category. However, an index can be easily turned into a column as we will see below.\n",
    "\n",
    "### set_index\n",
    "\n",
    "Every data frame has an index. When the dataframe is first created from scratch, the index keys are just integers ranging from 0 to `len(df)-1`. \n",
    "\n",
    "However it is often more useful to define and index from the values of one or several columns column.\n",
    "This is done by means of the `.set_index` method (in the `DataFrame` class).\n",
    "\n",
    "This method **makes the specified column into the new index **of the data frame by either taking it out of the data columns (default) or keeping it both as the index as well as a data column (by setting the drop parameter to False). More than one column may be set as index by inputing a list of columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember what `houses_df` looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that there is a column of apparently random numbers in boldface,  on the left, an it is *not named*. That's actually not a column, *but the index*. Notice that, when we defined the dataframe, we sorted it by SalePrice right after loading it from the csv. The first record in the resulting order by location actually comes from the 495-th row of the csv and corresponds to the house with the lowest price. That's where the 495 in front of the first record comes from. The second cheapest house was in line 916 and so forht."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the `.index` attribute we see that `houses_df` has an index consisting of integers, in the order just shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we redefine the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_indexed_1 = houses_df.set_index( 'Neighborhood' )\n",
    "houses_indexed_1.head( 20 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_indexed_1.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the index onsists of strings but they come from `Neighborhood` column in the original data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to see that setting an index on a data frame doesn't actually change the original data frame at all, rather it creates a new one with the specified index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_df.head(10) # this is the same as before. The original df wasn't altered by the indexing operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not let's define and index on two columns!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_indexed_2 = houses_df.set_index( ['Neighborhood', 'LotArea'] )\n",
    "houses_indexed_2.head( 20 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting index is called a _hierarchical_ index because it has a hierarchy of levels. \n",
    "\n",
    "In this case , the first level groups  records by Neighborhood an the second by LotArea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exercise I0: ** \n",
    "\n",
    "The following line generates an error. Copy an paste the *last* (non-empty) line of the error message into the answer. \n",
    "Make sure to understand **why** this error is produced. If you don't understand, discuss it with your instructor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_indexed_1['Neighborhood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_submit( \"I0\", \"copy and paste the last (non-empty) line of the error message including anything in red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we see that there is no longer a Neighborhood column. \n",
    "The indexing operation turned it into the index and removed it from the available columns. Remember an **index is not a data-column**, although it looks very much like one...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to keep a column as data as well as setting it as and index by  passing the `drop = False` to `set_index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "houses_indexed_1 = houses_df.set_index(\"Neighborhood\", drop=False)\n",
    "houses_indexed_1.head( 20 )  \n",
    "#Notice that 'Neighborhood' appears as a name for the index on the left but also as the 11-th column on the right..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving rows through an index -- basic usage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary purpose of an index is to *efficiently* retrieve a row or set of rows from a data frame. This is done throught the `DataFrame.loc` accessor ( 'loc' is short for 'locate' ). We will go in depth into the usage of `loc`, but for now the essential usage is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_row = houses_df.loc[916]\n",
    "second_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exercise I1: ** \n",
    "\n",
    "What is the _type_ of `second_row`?  (You can use the built-in function `type()` to answer this question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_submit( \"I1\", \"pandas.....fill-in rest of the type (fully-qualified) name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_row_v2 = houses_df.loc[ [826] ]\n",
    "second_row_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the same as before except that it is nicely formatted (why?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise I2**\n",
    "\n",
    "What is the type of `second_row_v2`? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_submit( \"I2\", \"pandas.....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_row = checkins_df.loc[ [0] ]\n",
    "another_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that a *single* index value can map to _many_ rows..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_indexed_1.loc['Edwards']  # All houses in the neighborhood called Edwards "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exercise I3 **\n",
    "\n",
    "How many rows are there for Neighborhood = 'OldTown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_submit( \"I3\",...  ) # your answer instead of ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing rows when there is a hierarchichal index \n",
    "\n",
    "When there are _n_ levels in the index, you can specify 1, 2 or up to 'n' values in to the `.loc` accessor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_indexed_2.loc[ 'Veenker' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_indexed_2.loc[ ('Veenker', 9600) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoid that nasty warning we are careful to sort both levels of the index.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_indexed_2s = houses_indexed_2.sort_index( level= [0,1], axis=0)  \n",
    "houses_indexed_2s.loc['Veenker'] #Notices areas are now sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_indexed_2s.loc[ ('Veenker',9600) ] #... and finding a houses by Lot Area is an efficient operation now. \n",
    "# No warning this time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reset_index\n",
    "\n",
    "It reset the index to an auto-incremental one and makes any previously set index a data column again. By default it resets all previously indexed columns, but the parameter level allows only certain indexes to be reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_indexed_2s.reset_index().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_indexed_2s.reset_index(level=1).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iloc and loc\n",
    "\n",
    "Pandas' main way of referencing data is through `.iloc` and `.loc` _accessors_ (which are special types of attributes)\n",
    "\n",
    "Both accesors are similar but only superficially so.\n",
    "\n",
    "`iloc` is simpler, it's basic usage syntax is as follows\n",
    "\n",
    "```\n",
    "   df.iloc[ list_of_ints_r, list_of_ints_c ]  \n",
    "```\n",
    "\n",
    "Here `list_of_ints_r` specifies the 0-based _integer indices_ of _rows_ in the dataframe's own order and and `list_of_ints_c` specifies the 0-based indices of `columns`. Despite its name `iloc` **does not take into account the dataframe's index** at all! The **`i`** in `iloc` stands for **`integer`**. \n",
    "\n",
    "Instead of `list_of_ints_r`, you can also put a slice, such as `10:47` to get rows numbered 10 through 46 (not including 47 as is usual with Python slicing). Remember that just writing `:47` is a shorthand for `0:47`  and `10:` is a shorthand for `10:len(df)`. Similarly just writing `:` means `0:len(df)`. \n",
    "\n",
    "Analogous considerations hold for the second argument, `list_of_ints_c`. \n",
    "\n",
    "\n",
    "Now onto `loc`.\n",
    "\n",
    "The `.loc` method (accessor)  receives as input list of row keys and another one column names.\n",
    "\n",
    "Row keys are the keys defined in the index. The colum names are the regular column names you already know and love. \n",
    "\n",
    "\n",
    "The basic syntax is:\n",
    "\n",
    "```\n",
    "   df.loc[ list_of_row_keys, list_of_col_names ]  \n",
    "```\n",
    "\n",
    "It is also possible to  specify the _row keys_ only:\n",
    "\n",
    "```\n",
    "   df.loc[ list_of_row_keys ]  \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_indexed_1.iloc[ [1,2,3], [0, 1,3] ]  # just indexing by the order they appear in the df. 0-based indexing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_indexed_1.iloc[ 1:7, 0:5 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use `.loc` with only row keys: \n",
    "\n",
    "Notice that a **single key can refer to many rows**! (and this is not unusual...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_indexed_1.loc[ [\"Blueste\",\"NPkVill\"] ].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses_indexed_1.loc[ [\"Blueste\",\"NPkVill\"], 'LotArea' : 'LandContour' ].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that only some of the values of 'Exterior1st' appeared for `Street = 'Grvl'`, hence the grid contains NaNs for those.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"joining\"></div>\n",
    "## Merge and join\n",
    "\n",
    "Joining refers to any operation where rows from one table `A` are combined (concatenated) with rows from another table `B` following a certain \"lookup\" or \"linkage\" rule. This rule usually takes the form `rowA.idcol1 = rowB.idcol2`, that is the value from `idcol1` in `rowA` coming from table `A` should match the value of `idcol2`  in `rowB` from table `B`, in order for both rows to be concatenated and their concatenation return as part of the result. This type of rule defines an **equi-join** (*equi* because the comparison is *equality*)\n",
    "\n",
    "Pandas dataframes, implement to methods for joining. \n",
    "These are  `.merge()` and `.join()`.\n",
    "\n",
    "### `.merge()`\n",
    "\n",
    "Somewhat counterintutively, the function `merge` is *pandas counterpart of SQL's equi-join*, and requires the specification of which columns of both data frames would be compared. Merge doesn't care at all about the indexes defined on the deframe. \n",
    "\n",
    "\n",
    "### The four types of join\n",
    "\n",
    "The following figure summarizes the different 4 types or merge: ** inner, outer, left and right**\n",
    "\n",
    "The function merge is also availaible as a method in the  `DataFrame` class. \n",
    "The basic syntax is:\n",
    "\n",
    "```\n",
    "new_joined_df = df.merge( another_df, left_on = \"col_in_df\",  right_on = \"col_in_another_df\",\n",
    "                          how=\"inner\"|\"left\"|\"right\"|\"outer\" ) \n",
    "```\n",
    "\n",
    "The first argument (`another_df`) as well as `left_on` and `right_on` are required arguments. \n",
    "`left_on` specifies a column name on the data frame `df` whose values should be matched with \n",
    "those of the  `another_df`'s column specified by `right_on` in. \n",
    "\n",
    "The `how` argument is optional ans specifies the type of join:\n",
    " \n",
    " <img src=\"merge.png\" height=\"200\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see some examples, we load some (financial!) data first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdcop = pd.read_csv( DATA_DIR + 'usdcop.csv', delimiter = \"\\t\", infer_datetime_format=True)\n",
    "usdcop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minor prepossing to have alues as proper numbers and not strings...\n",
    "\n",
    "usdcop = pd.read_csv( DATA_DIR + 'usdcop.csv', delimiter = \"\\t\", infer_datetime_format=True)\n",
    "usdcop['usd_cop'] = usdcop['usd_cop'].str.replace('$', '').str.replace(',', '').astype( float )\n",
    "usdcop['fecha'] = ( usdcop['fecha'].str[6:10] + '-' + usdcop['fecha'].str[3:5] + '-' + usdcop['fecha'].str[0:2] )\n",
    "usdcop  # Now contains the exchange rate from usd to cop  as type float!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btcusd = pd.read_csv( DATA_DIR + 'btcusd.csv' ) # this file contains hourly exchange rate from BTC (bitcoin) to USD\n",
    "btcusd['date'] = btcusd['date_tm'].str[0:10]\n",
    "btcusd['time'] = btcusd['date_tm'].str[11:]\n",
    "\n",
    "btcusd.head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btcusd_day_max = btcusd.groupby('date').agg( {'btc_usd' : 'max' } ).reset_index()\n",
    "btcusd_day_min = btcusd.groupby('date').agg( {'btc_usd' : 'min' } ).reset_index()\n",
    "btcusd_day = pd.concat( [btcusd_day_max, btcusd_day_min] ).sort_values( 'date' )\n",
    "btcusd_day  # Now contains both the minimum and maximum exchange rates between btc (bitcoin) and USD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner merge\n",
    "\n",
    "Is the default merge in case the `how` parameter is not specified. It yields rows for which **there are matching values of the specified merge columns on both** data_Frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdcop.merge( btcusd_day_min, left_on='fecha', right_on='date' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Why did the first `btc_usd` price (7930.79) get duplicated?  If you don't understand it, discuss it with your instructor! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdcop.merge( btcusd_day, left_on='fecha', right_on='date' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left merge\n",
    "\n",
    "It gkeeps all the data from the first data frame, adding data from the second one whenever there is a row matching and filling with `NaN` the missing columns from the second data frame in which no match was found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdcop.merge( btcusd_day_min, how=\"left\", left_on='fecha', right_on='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Right merge\n",
    "\n",
    "It's pretty much the same exact thing as left merge with the data frame on the left taking being on the right and viceversa. It keeps all the data from the second data frame adding data from the first one whenever they intersect and filling with `NaN` the missing columns from the first data frame if no match was found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdcop.merge( btcusd_day_min,  how=\"right\", left_on='fecha', right_on='date').sort_values( 'date' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outer merge\n",
    "\n",
    "It's basically the combination of both left and right join, keeping all the data from both data frames and filling out with NaN if no match found was found for either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usdcop.merge( btcusd_day_min, how=\"outer\", left_on='fecha', right_on='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Exercise 0 \n",
    "\n",
    "Compute the outer merge between the `usdcop` and `btcusd_day` dataframes on `fecha`/`date`. \n",
    "\n",
    "Call the resulting data frame `buc_min`. \n",
    "\n",
    "Add a new column `btc_cop` to this dataframe containing the exchange rate from `btc` to `cop`. This can be computed as the product of the two available exchange rates (`btc_usd`, `usd_cop`). \n",
    "\n",
    "Now generate a new series `agg` by applying `groupby('date')` to `buc_min` and compute both the mean and the median of the new column for each `date`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace ... by your code \n",
    "buc_min = ... \n",
    "...\n",
    "agg = buc_min.groupby('date').agg( {\"btc_cop\" : [\"mean\", \"median\"]} ) \n",
    "\n",
    "ans_submit( 'Mer0', int(agg[('btc_cop', 'median')].sum()) ) # don't change this line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join\n",
    "\n",
    "The second method for joining is `.join()`. The main difference with `.merge()` is that it takes advantage of any indices already defined on the dataframes to be joined and, due to this, could potentially be more efficient in some cases.\n",
    "\n",
    "Sometimes, when data frames are already indexed by the same 'thing', it is a lot easier to use `join`, which simply matches rows from two them according to their index value. \n",
    "\n",
    "To see this, let's create another dataframe indexed by 'Neighborhood'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats_by_neighborhood = ( houses_df.groupby( \"Neighborhood\" )\n",
    "                                   .agg( { \"LotArea\" : \"mean\",\n",
    "                                           \"SalePrice\" : \"mean\"}) \n",
    "                                   .rename( columns={\n",
    "                                              \"LotArea\" : \"avg_area_in_nbh\", #nbh : Neighborhood\n",
    "                                              \"SalePrice\" : \"avg_price_in_nbh\"}) \n",
    "                        )\n",
    "\n",
    "stats_by_neighborhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets join against (a selection of the columns in) `houses_indexed_1` which was already indexed by `Neighborhood`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "( houses_indexed_1[['MSSubClass', 'LotFrontage', 'LotArea', 'SalePrice']]\n",
    "                  .join( stats_by_neighborhood ) # notice we don't have to specify any columns to join on, as the indexes are used implicitely!\n",
    "                  .sort_values( 'SalePrice')\n",
    ").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exercise Mer1 ** \n",
    "\n",
    "We define a dataframe aggregated (and indexed!) by lotarea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_by_area = ( houses_df.groupby(\"LotArea\")\n",
    "                              .agg( { \"SalePrice\" : \"mean\", \"LotFrontage\" : \"mean\" } )\n",
    "                              .rename( columns={ \"SalePrice\" : \"mean_price_area\", \"LotFrontage\" : \"min_frontage_area\"  }) )\n",
    "stats_by_area.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, define a `houses_by_area`  as `houses_df` indexed by `LotArea` and join the result via `.join()` with `stats_by_lotarea`. \n",
    "How many rows does the resulting join df have? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_submit( \"Mer1\", 0 ) # replace 0 by the number of rows in the resulting joined df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
